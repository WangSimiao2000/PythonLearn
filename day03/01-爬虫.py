"""
爬虫基础
    什么是爬虫
        是一种按照一定的规则,自动地抓取万维网信息的程序或脚本
    爬虫的分类
        通用网络爬虫
            根据一个种子url链接,扩展至整个web页面
            百度,必应,谷歌,360
        聚焦网络爬虫(主题)
            有目的的进行爬取
        增量式网络爬虫
            是指对已经下载的网站采取增量式更新和只爬行新产生的货已经发生变化的网页的爬虫
        深度式网络爬虫
            需要提交表单信息的,或需要传递一些参数,才可以访问数据

    爬虫的原理

    数据的分类
        用户产生的数据,微信数据,抖音
        政府的数据
        公司管理的数据
        自己爬的数据

    数据能干什么
        人工智能,机器学习,数据分析
        卖

    robots协议
        网站和爬虫协商的协议,网站中的某些站点不允许爬虫的访问

"""